<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Changqian Yu </title> <meta name="author" content="Changqian Yu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="yu-changqian"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%95&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yu-changqian.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">Awards &amp; Services </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Changqian Yu </h1> <p class="desc">Senior Research Scientist@Kunlun Tech, Ex-Research Scientist@Meituan, Intern@MSRA, Megvii</p> </header> <article> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bio_pic-480.webp 480w,/assets/img/bio_pic-800.webp 800w,/assets/img/bio_pic-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/bio_pic.jpg?e75cb71f26bfea0ea08ce762b8a144b4" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="bio_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <a href="/assets/pdf/cv.pdf"><i class="ai ai-cv-square ai-2x"></i></a> <a href="https://www.linkedin.com/in/yu-changqian/" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin fa-2x"></i></a> <a href="https://scholar.google.com/citations?user=Hv-vj2sAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar-square ai-2x"></i></a> <a href="https://github.com/yu-changqian" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-square-github fa-2x"></i></a> <a href="https://x.com/ChangqianYu" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-square-x-twitter fa-2x"></i></a> <a href="https://www.zhihu.com/people/yu-chang-qian" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-zhihu fa-2x"></i></a> </div> </div> <div class="clearfix"> <p>As a Senior Research Scientist at <strong>Kunlun Tech</strong>, I lead a team developing cutting-edge large multimodal models, with expertise in Diffusion and VLM technologies. My tenure at <strong>Meituanâ€™s Autonomous Delivery Department</strong> as a Research Scientist equipped me with a robust understanding of real-world applications of AI.</p> <p>I obtained my Ph.D. degree from School of Artificial Intelligence and Automation,Â <strong>Huazhong University of Science and Technology</strong>Â in 2021, under the expert guidance of <a href="https://scholar.google.com/citations?user=ky_ZowEAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Prof.Â Nong Sang</a>Â and <a href="https://scholar.google.com/citations?user=4tku-lwAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Prof.Â Changxin Gao</a>. My academic journey was further enriched by a visiting Ph.D. position at the Australian Institute for Machine Learning, <strong>University of Adelaide</strong>, where I worked closely with <a href="https://scholar.google.com/citations?user=Ljk2BvIAAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Prof. Chunhua Shen</a>. During my doctoral studies, I received the <strong>Excellent Doctoral Dissertation Award</strong> (one of only 10 students in the country).</p> <p>My industry experience includes being a research intern at <strong>Microsoft Research Asia</strong> and <strong>Megvii (Face++)</strong>, where I collaborated with <a href="https://jingdongwang2017.github.io/" rel="external nofollow noopener" target="_blank">Dr. Jingdong Wang</a>, <a href="https://www.skicyyu.org/" rel="external nofollow noopener" target="_blank">Dr. Gang Yu</a>, and <a href="https://scholar.google.com/citations?user=ALVSZAYAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Dr. Jian Sun</a>. I was part of the winning team at the COCO &amp; Mapillary Panoptic Segmentation Challenge 2018.</p> <p>My passion lies in tackling complex problems in computer vision and artificial intelligence. I have made significant contributions to the fields of semantic/panoptic segmentation, behavior prediction, and vision-language models. Among my most notable works are:</p> <ul> <li> <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Changqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.html" rel="external nofollow noopener" target="_blank">BiSeNet</a> (Rank 10 in ECCV 2018 Top-10 Influential Papers &amp; Citation &gt; 2500).</li> <li> <a href="https://link.springer.com/article/10.1007/s11263-021-01515-2" rel="external nofollow noopener" target="_blank">BiSeNetV2</a> (IJCV &amp; ESI &amp; ESI-Hot &amp; Citation &gt; 1000).</li> <li> <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Learning_a_Discriminative_CVPR_2018_paper.html" rel="external nofollow noopener" target="_blank">DFNet</a> (CVPR &amp; Citation &gt; 900)</li> <li> <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Lite-HRNet_A_Lightweight_High-Resolution_Network_CVPR_2021_paper.html" rel="external nofollow noopener" target="_blank">Lite-HRNet</a> (CVPR &amp; Citation &gt; 300)</li> </ul> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 12%">Oct 04, 2023</th> <td> Ranked as the <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/6" rel="external nofollow noopener" target="_blank">Worldâ€™s Top 2% most-cited scientists 2023 by Stanford University</a>. </td> </tr> <tr> <th scope="row" style="width: 12%">Nov 23, 2022</th> <td> Delighted to receive <a href="https://m.csig.org.cn/59/202211/50800.html" rel="external nofollow noopener" target="_blank">CSIG Excellent Doctoral Dissertation Award/ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼šä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡å¥–</a> {<a href="https://m.csig.org.cn/67/202304/50860.html" rel="external nofollow noopener" target="_blank">Media Reports</a>}. </td> </tr> <tr> <th scope="row" style="width: 12%">Sep 03, 2022</th> <td> The IJCV Paper of BiSeNetV2 has been selected as the ESI Paper and ESI-Hot PaperğŸ”¥ </td> </tr> <tr> <th scope="row" style="width: 12%">Aug 15, 2022</th> <td> Thank Bilibili Vlogger â€œåœ¨ä¸‹å°è‹â€ for the nice interview. {<a href="https://www.bilibili.com/video/BV1VW4y1t7iW/?spm_id_from=333.788" rel="external nofollow noopener" target="_blank">Bilibili Video 1</a>} {<a href="https://www.bilibili.com/video/BV1zr4y1y7Pf/?spm_id_from=333.999.0.0" rel="external nofollow noopener" target="_blank">Bilibili Video 2</a>} {<a href="https://www.youtube.com/watch?v=jkxAu8MwAwU" rel="external nofollow noopener" target="_blank">Youtube Video</a>}. </td> </tr> <tr> <th scope="row" style="width: 12%">Jun 15, 2021</th> <td> Successfully defended my Ph.D. thesis! </td> </tr> <tr> <th scope="row" style="width: 12%">Sep 26, 2018</th> <td> As a team member of Megvii(Face++) and R4D Team, we won the 1st place of COCO Panoptic Segmentation and Mapillary Panoptic Segmentation in the <a href="https://cocodataset.org/workshop/coco-mapillary-eccv-2018.html" rel="external nofollow noopener" target="_blank">COCO &amp; Mapillary Panoptic Segmentation Challenge 2018</a>. I was invited to present at COCO &amp; Mapillary Joint Workshop at ECCV2018 in Munich, Germany. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>ECCV</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/bisenet_preview-480.webp 480w,/assets/img/publication_preview/bisenet_preview-800.webp 800w,/assets/img/publication_preview/bisenet_preview-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/bisenet_preview.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="bisenet_preview.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yu2018bisenet" class="col-sm-9"> <div class="title">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</div> <div class="author"> <em>Changqian Yu<sup>*</sup></em>,Â Jingbo Wang<sup>*</sup>,Â Chao Peng,Â Changxin Gao<sup>â€ </sup>,Â Gang Yu,Â andÂ Nong Sang </div> <div class="periodical"> In <em>European Conference on Computer Vision</em> (<b>ECCV</b>) , 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">ECCV 2018 Top-10 Influential Papers</a> <a href="http://arxiv.org/abs/1808.00897" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Changqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/yu-changqian/TorchSeg/tree/master/model/bisenet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:UeHWp8X0CEIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2.7K-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2.7K Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Rank 10 in ECCV 2018 Top-10 Influential Papers</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yu2018bisenet</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Changqian and Wang, Jingbo and Peng, Chao and Gao, Changxin and Yu, Gang and Sang, Nong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{325--341}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{UeHWp8X0CEIC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>IJCV</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/bisenetv2-480.webp 480w,/assets/img/publication_preview/bisenetv2-800.webp 800w,/assets/img/publication_preview/bisenetv2-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/bisenetv2.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="bisenetv2.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yu2021bisenet" class="col-sm-9"> <div class="title">BiSeNet V2: Bilateral Network with Guided Aggregation for Real-time Semantic Segmentation</div> <div class="author"> <em>Changqian Yu</em>,Â Changxin Gao<sup>â€ </sup>,Â Jingbo Wang,Â Gang Yu,Â Chunhua Shen,Â andÂ Nong Sang </div> <div class="periodical"> <em>International Journal of Computer Vision</em> (<b>IJCV</b>), 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">ESI-Hot</a> <a href="http://arxiv.org/abs/2004.02147" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s11263-021-01515-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/yu-changqian/TorchSeg/tree/master/model/bisenet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:Y0pCki6q_DkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1.2K-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1.2K Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>ESI-Hot Paper &amp; ESI-Highly Cited Paper</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yu2021bisenet</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BiSeNet V2: Bilateral Network with Guided Aggregation for Real-time Semantic Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Changqian and Gao, Changxin and Wang, Jingbo and Yu, Gang and Shen, Chunhua and Sang, Nong}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Computer Vision}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{129}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3051--3068}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Y0pCki6q_DkC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>CVPR</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dfnet-480.webp 480w,/assets/img/publication_preview/dfnet-800.webp 800w,/assets/img/publication_preview/dfnet-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/dfnet.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="dfnet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yu2018learning" class="col-sm-9"> <div class="title">Learning a Discriminative Feature Network for Semantic Segmentation</div> <div class="author"> <em>Changqian Yu</em>,Â Jingbo Wang,Â Chao Peng,Â Changxin Gao,Â Gang Yu,Â andÂ Nong Sang </div> <div class="periodical"> In <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>) , 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1804.09337" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Learning_a_Discriminative_CVPR_2018_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/yu-changqian/TorchSeg/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-940-4285F4?logo=googlescholar&amp;labelColor=beige" alt="940 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yu2018learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning a Discriminative Feature Network for Semantic Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Changqian and Wang, Jingbo and Peng, Chao and Gao, Changxin and Yu, Gang and Sang, Nong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1857--1866}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{u5HHmVD_uO8C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>CVPR</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/litehrnet-480.webp 480w,/assets/img/publication_preview/litehrnet-800.webp 800w,/assets/img/publication_preview/litehrnet-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/litehrnet.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="litehrnet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yu2021lite" class="col-sm-9"> <div class="title">Lite-HRNet: A Lightweight High-Resolution Network</div> <div class="author"> <em>Changqian Yu</em>,Â Bin Xiao,Â Changxin Gao,Â Lu Yuan,Â Lei Zhang,Â Nong Sang,Â andÂ Jingdong Wang </div> <div class="periodical"> In <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>) , 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2104.06403" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Lite-HRNet_A_Lightweight_High-Resolution_Network_CVPR_2021_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/HRNet/Lite-HRNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:WF5omc3nYNoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-400-4285F4?logo=googlescholar&amp;labelColor=beige" alt="400 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yu2021lite</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Lite-HRNet: A Lightweight High-Resolution Network}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Changqian and Xiao, Bin and Gao, Changxin and Yuan, Lu and Zhang, Lei and Sang, Nong and Wang, Jingdong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10440--10450}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{WF5omc3nYNoC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>CVPR</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cpnet-480.webp 480w,/assets/img/publication_preview/cpnet-800.webp 800w,/assets/img/publication_preview/cpnet-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/cpnet.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="cpnet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yu2020context" class="col-sm-9"> <div class="title">Context prior for scene segmentation</div> <div class="author"> <em>Changqian Yu</em>,Â Jingbo Wang,Â Changxin Gao,Â Gang Yu,Â Chunhua Shen,Â andÂ Nong Sang </div> <div class="periodical"> In <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>) , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2004.01547" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Yu_Context_Prior_for_Scene_Segmentation_CVPR_2020_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/yu-changqian/ContextPrior" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-300-4285F4?logo=googlescholar&amp;labelColor=beige" alt="300 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yu2020context</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Context prior for scene segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Changqian and Wang, Jingbo and Gao, Changxin and Yu, Gang and Shen, Chunhua and Sang, Nong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{12416--12425}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Tyk-4Ss8FVUC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>ECCV</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rgnet-480.webp 480w,/assets/img/publication_preview/rgnet-800.webp 800w,/assets/img/publication_preview/rgnet-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/rgnet.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="rgnet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yu2020representative" class="col-sm-9"> <div class="title">Representative Graph Neural Network</div> <div class="author"> <em>Changqian Yu</em>,Â Yifan Liu,Â Changxin Gao,Â Chunhua Shen,Â andÂ Nong Sang </div> <div class="periodical"> In <em>European Conference on Computer Vision</em> (<b>ECCV</b>) , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2008.05202" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-58571-6_23" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:W7OEmFMy1HYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-50-4285F4?logo=googlescholar&amp;labelColor=beige" alt="50 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yu2020representative</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Representative Graph Neural Network}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Changqian and Liu, Yifan and Gao, Changxin and Shen, Chunhua and Sang, Nong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{379--396}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{W7OEmFMy1HYC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50">IEEE SPL</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/condnet-480.webp 480w,/assets/img/publication_preview/condnet-800.webp 800w,/assets/img/publication_preview/condnet-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/condnet.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="condnet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="yu2021condnet" class="col-sm-9"> <div class="title">CondNet: Conditional Classifier for Scene Segmentation</div> <div class="author"> <em>Changqian Yu</em>,Â Yuanjie Shao,Â Changxin Gao,Â andÂ Nong Sang </div> <div class="periodical"> <em>IEEE Signal Processing Letters</em> (<b>IEEE SPL</b>), 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2109.10322" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9393566/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/yu-changqian/CondNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:ufrVoPGSRksC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-14-4285F4?logo=googlescholar&amp;labelColor=beige" alt="14 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yu2021condnet</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CondNet: Conditional Classifier for Scene Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Changqian and Shao, Yuanjie and Gao, Changxin and Sang, Nong}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Signal Processing Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{758--762}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{ufrVoPGSRksC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50">IEEE TMM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hymo-480.webp 480w,/assets/img/publication_preview/hymo-800.webp 800w,/assets/img/publication_preview/hymo-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/hymo.jpg" class="preview z-depth-1 rounded" width="180px" height="120px" alt="hymo.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="meng2023hybrid" class="col-sm-9"> <div class="title">Hybrid motion representation learning for prediction from raw sensor data</div> <div class="author"> Depu Meng,Â <em>Changqian Yu<sup>â€ </sup></em>,Â Jiajun Deng,Â Deheng Qian,Â Houqiang Li,Â andÂ Dongchun Ren </div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em> (<b>IEEE TMM</b>), 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10040996" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:MXK_kJrjxJIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">meng2023hybrid</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid motion representation learning for prediction from raw sensor data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Meng, Depu and Yu, Changqian and Deng, Jiajun and Qian, Deheng and Li, Houqiang and Ren, Dongchun}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Multimedia}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8868--8879}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{MXK_kJrjxJIC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>NeurIPS</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/plip-480.webp 480w,/assets/img/publication_preview/plip-800.webp 800w,/assets/img/publication_preview/plip-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/plip.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="plip.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zuo2023plip" class="col-sm-9"> <div class="title">PLIP: Language-Image Pre-training for Person Representation Learning</div> <div class="author"> Jialong Zuo,Â Jiahao Hong,Â Feng Zhang,Â <em>Changqian Yu</em>,Â Hanyu Zhou,Â Changxin Gao,Â Nong Sang,Â andÂ Jingdong Wang </div> <div class="periodical"> In <em>Annual Conference on Neural Information Processing Systems</em> (<b>NeurIPS</b>) , 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2305.08386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/Zplusdragon/PLIP" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:3fE2CSJIrl8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-24-4285F4?logo=googlescholar&amp;labelColor=beige" alt="24 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zuo2023plip</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PLIP: Language-Image Pre-training for Person Representation Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zuo, Jialong and Hong, Jiahao and Zhang, Feng and Yu, Changqian and Zhou, Hanyu and Gao, Changxin and Sang, Nong and Wang, Jingdong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Annual Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{3fE2CSJIrl8C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fluxmusic-480.webp 480w,/assets/img/publication_preview/fluxmusic-800.webp 800w,/assets/img/publication_preview/fluxmusic-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/fluxmusic.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="fluxmusic.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="fei2024flux" class="col-sm-9"> <div class="title">FLUX that Plays Music</div> <div class="author"> Zhengcong Fei,Â Mingyuan Fan,Â <em>Changqian Yu</em>,Â andÂ Junshi Huang </div> <div class="periodical"> <em>arXiv preprint</em> (<b>arXiv</b>), 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2409.00587" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/feizc/FluxMusic" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:M3ejUd6NZC8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">fei2024flux</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FLUX that Plays Music}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fei, Zhengcong and Fan, Mingyuan and Yu, Changqian and Huang, Junshi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{M3ejUd6NZC8C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dit-moe-480.webp 480w,/assets/img/publication_preview/dit-moe-800.webp 800w,/assets/img/publication_preview/dit-moe-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/dit-moe.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="dit-moe.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="fei2024scaling" class="col-sm-9"> <div class="title">Scaling Diffusion Transformers to 16 Billion Parameters</div> <div class="author"> Zhengcong Fei,Â Mingyuan Fan,Â <em>Changqian Yu</em>,Â Debang Li,Â andÂ Junshi Huang </div> <div class="periodical"> <em>arXiv preprint</em> (<b>arXiv</b>), 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2407.11633" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/feizc/DiT-MoE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:4TOpqqG69KYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">fei2024scaling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Scaling Diffusion Transformers to 16 Billion Parameters}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fei, Zhengcong and Fan, Mingyuan and Yu, Changqian and Li, Debang and Huang, Junshi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{4TOpqqG69KYC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dimba-480.webp 480w,/assets/img/publication_preview/dimba-800.webp 800w,/assets/img/publication_preview/dimba-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/dimba.jpg" class="preview z-depth-1 rounded" width="180px" height="120px" alt="dimba.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="fei2024dimba" class="col-sm-9"> <div class="title">Dimba: Transformer-Mamba Diffusion Models</div> <div class="author"> Zhengcong Fei,Â Mingyuan Fan,Â <em>Changqian Yu</em>,Â Debang Li,Â Youqiang Zhang,Â andÂ Junshi Huang </div> <div class="periodical"> <em>arXiv preprint</em> (<b>arXiv</b>), 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2406.01159" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dimba-project.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/feizc/Dimba" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:YOwf2qJgpHMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">fei2024dimba</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dimba: Transformer-Mamba Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fei, Zhengcong and Fan, Mingyuan and Yu, Changqian and Li, Debang and Zhang, Youqiang and Huang, Junshi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{YOwf2qJgpHMC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dis-480.webp 480w,/assets/img/publication_preview/dis-800.webp 800w,/assets/img/publication_preview/dis-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/dis.jpg" class="preview z-depth-1 rounded" width="180px" height="120px" alt="dis.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="fei2024scalable" class="col-sm-9"> <div class="title">Scalable diffusion models with state space backbone</div> <div class="author"> Zhengcong Fei,Â Mingyuan Fan,Â <em>Changqian Yu</em>,Â andÂ Junshi Huang </div> <div class="periodical"> <em>arXiv preprint</em> (<b>arXiv</b>), 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2402.05608" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/feizc/DiS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:Zph67rFs4hoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-19-4285F4?logo=googlescholar&amp;labelColor=beige" alt="19 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">fei2024scalable</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Scalable diffusion models with state space backbone}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fei, Zhengcong and Fan, Mingyuan and Yu, Changqian and Huang, Junshi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{Zph67rFs4hoC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50">IEEE TIP</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cbl-480.webp 480w,/assets/img/publication_preview/cbl-800.webp 800w,/assets/img/publication_preview/cbl-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/cbl.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="cbl.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="wu2023conditional" class="col-sm-9"> <div class="title">Conditional boundary loss for semantic segmentation</div> <div class="author"> Dongyue Wu,Â Zilin Guo,Â Aoyan Li,Â <em>Changqian Yu</em>,Â Changxin Gao,Â andÂ Nong Sang </div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em> (<b>IEEE TIP</b>), 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10173725" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/dywu98/CBL-Conditional-Boundary-Loss" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:kNdYIx-mwKoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-19-4285F4?logo=googlescholar&amp;labelColor=beige" alt="19 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wu2023conditional</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Conditional boundary loss for semantic segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Dongyue and Guo, Zilin and Li, Aoyan and Yu, Changqian and Gao, Changxin and Sang, Nong}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Image Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{kNdYIx-mwKoC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>CVPR</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/oanet-480.webp 480w,/assets/img/publication_preview/oanet-800.webp 800w,/assets/img/publication_preview/oanet-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/oanet.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="oanet.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2019end" class="col-sm-9"> <div class="title">An End-to-End Network for Panoptic Segmentation</div> <div class="author"> Huanyu Liu,Â Chao Peng,Â <em>Changqian Yu</em>,Â Jingbo Wang,Â Xu Liu,Â Gang Yu,Â andÂ Wei Jiang </div> <div class="periodical"> In <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>) , 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1903.05027" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_An_End-To-End_Network_for_Panoptic_Segmentation_CVPR_2019_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-200-4285F4?logo=googlescholar&amp;labelColor=beige" alt="200 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2019end</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An End-to-End Network for Panoptic Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Huanyu and Peng, Chao and Yu, Changqian and Wang, Jingbo and Liu, Xu and Yu, Gang and Jiang, Wei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6172--6181}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{2osOgNQ5qMEC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge w-50" style="background-color:#00369f"> <div>ECCV</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/vidseg-480.webp 480w,/assets/img/publication_preview/vidseg-800.webp 800w,/assets/img/publication_preview/vidseg-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="/assets/img/publication_preview/vidseg.png" class="preview z-depth-1 rounded" width="180px" height="120px" alt="vidseg.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2020efficient" class="col-sm-9"> <div class="title">Efficient Semantic Video Segmentation with Per-frame Inference</div> <div class="author"> Yifan Liu,Â Chunhua Shen,Â <em>Changqian Yu</em>,Â andÂ Jingdong Wang </div> <div class="periodical"> In <em>European Conference on Computer Vision</em> (<b>ECCV</b>) , 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2002.11433" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-58607-2_21" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/irfanICMLL/ETC-Real-time-Per-frame-Semantic-video-segmentation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=Hv-vj2sAAAAJ&amp;citation_for_view=Hv-vj2sAAAAJ:zYLM7Y9cAGgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-150-4285F4?logo=googlescholar&amp;labelColor=beige" alt="150 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2020efficient</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient Semantic Video Segmentation with Per-frame Inference}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Yifan and Shen, Chunhua and Yu, Changqian and Wang, Jingdong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{352--368}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{zYLM7Y9cAGgC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2024 Changqian Yu. Photos taken in Japan by my wife Mengqi Du. Last updated: October 08, 2024. <img src="https://badges.toozhao.com/badges/01J3HPVQESCZP39CKV4YD5EGMV/blue.svg"> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>